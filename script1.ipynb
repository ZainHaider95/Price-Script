{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rocky-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-front",
   "metadata": {},
   "source": [
    "## Setup Stuff (that should come from config files or database later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_TRANSACTION_FEE = 0.0101\n",
    "CHANNELS = [\n",
    "    {'name':'AP Fusion', 'channel_transaction_fee':0.08, 'target_profit': 0.09},\n",
    "\n",
    "    {'name':'PS Amazon', 'channel_transaction_fee':0.119},\n",
    "    {'name':'PS Walmart', 'channel_transaction_fee':0.125},\n",
    "    {'name':'PS Ebay', 'channel_transaction_fee':0.17}, ## Changed from 0.15 on Feb 24 2022\n",
    "    \n",
    "    {'name':'BS Amazon', 'channel_transaction_fee':0.12},\n",
    "    {'name':'BS Walmart', 'channel_transaction_fee':0.12},\n",
    "    {'name':'BS Ebay', 'channel_transaction_fee':0.12},\n",
    "    \n",
    "    {'name':'Mecka', 'channel_transaction_fee': 0.12}\n",
    "]\n",
    "\n",
    "WAREHOUSES = [\n",
    "    # Fully integrated warehouses\n",
    "    {'key':'C', 'name':'Brock', 'shipping':'free-ish'},\n",
    "    {'key':'D', 'name':'Dorman Direct', 'shipping':'free-ish', 'target_profit': 0.6},\n",
    "    {'key':'J', 'name':'PFG', 'shipping':'theirs'},\n",
    "    {'key':'K', 'name':'Keystone', 'shipping':'theirs'},\n",
    "    {'key':'N', 'name':'NPW', 'shipping':'ours'},\n",
    "    {'key':'O', 'name':'Tonsa', 'shipping':'ours'},\n",
    "    {'key':'P', 'name':'Parts Auth', 'shipping':'theirs'},\n",
    "    {'key':'Y', 'name':'Motor State', 'shipping':'theirs'},\n",
    "    # Manual/FTP warehouses\n",
    "    {'key':'1', 'name':'Jante Wheel', 'shipping':'free'},\n",
    "    {'key':'2', 'name':'OE Wheels', 'shipping':'theirs'},\n",
    "    {'key':'6', 'name':'Burco Mirrors', 'shipping':'ours'},\n",
    "    {'key':'8', 'name':'Race Sport Lighting', 'shipping':'ours', 'target_profit': 0.1},\n",
    "    {'key':'9', 'name':'Sunbelt APG', 'shipping':'ours'},\n",
    "    # Low-volume, or unused warehouses\n",
    "    #{'key':'5', 'name':'KSI Trading'},\n",
    "    #{'key':'7', 'name':'NTW'},\n",
    "    #{'key':'H', 'name':'Hanson'},\n",
    "    #{'key':'3', 'name':'Motor State'},\n",
    "]\n",
    "\n",
    "def get_warehouse_key(warehouse_name):\n",
    "    for warehouse in WAREHOUSES:\n",
    "        if warehouse['name'] == warehouse_name:\n",
    "            return warehouse['key']\n",
    "    return None\n",
    "\n",
    "\n",
    "DEFAULT_TARGET_PROFIT = 0.05\n",
    "DEFAULT_SHIP_MARKUP = 1 / 1.12\n",
    "EXCLUDED_WAREHOUSES = ['A','5','7','H','3']\n",
    "PUNCTUATION_WAREHOUSES = ['J','1','C', '9', '8', 'Y']\n",
    "\n",
    "PARTS_AUTH_SHIPPING_MODEL = 'shipping-research/tree-model.pkl'\n",
    "\n",
    "PRICE_FILE_COLUMNS = ['CS-SKU-NP', 'MinPrice', 'Shipping', 'Carrier', 'Service', 'Markup',\n",
    "       'ShipMkup', 'ListMkup', 'PackQty', 'MinQty', 'MaxQty', 'Zip Code',\n",
    "       'CatSKU', 'OP-Lowest(Y)', 'VND-Lowest(Y)', 'MinMkDown', 'MaxMkUp', 'Interval',\n",
    "       'BundleSK', 'Duplicate']\n",
    "\n",
    "PRICE_FILE_LOCATION = 'price-files'\n",
    "\n",
    "CatSKU_CHANNELS = ['PS Ebay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-archive",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-retro",
   "metadata": {},
   "source": [
    "#### Load in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = pd.read_csv('inventory/pw-all.csv', low_memory=False, \n",
    "                 dtype={'MasterLC':'Int64', 'Zip Code': str})\n",
    "# pw['MasterLC'] = pw['MasterLC'].astype('Int64')\n",
    "\n",
    "# Temporarily remove all NPW.\n",
    "##pw = pw[pw['WD'] != 'N']\n",
    "\n",
    "warehouses = pw['WD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-sessions",
   "metadata": {},
   "source": [
    "## Top-level processing and filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-diagram",
   "metadata": {},
   "source": [
    "#### Sad updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excessive-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the Line Code and CS-SKU-NP for Brock\n",
    "pw.loc[pw['WD']=='C', 'CS-SKU-NP'] = pw.loc[pw['WD']=='C', 'CS-SKU']\n",
    "pw.loc[(pw['MasterLC']==158) & (pw['LC']=='429'), 'MasterLC'] = 429"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-broadcasting",
   "metadata": {},
   "source": [
    "#### Preprocess price file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "endangered-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prices = pd.read_csv('maps.csv')\n",
    "map_prices = map_prices.sort_values('CS-SKU-NP').drop_duplicates(subset=['CS-SKU-NP'])\n",
    "map_prices = map_prices.set_index('CS-SKU-NP')['MAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sticky-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate column for managing costs vs MinPrice to avoid confusion.\n",
    "pw['item_cost'] = pw['MinPrice']\n",
    "\n",
    "# update Dorman costs (which are per-pack initally) to be per-unit\n",
    "dorman_update_idx = (pw['WD']=='D') & (pw['PackQty'].notna())\n",
    "pw.loc[dorman_update_idx, 'item_cost'] = pw.loc[dorman_update_idx, 'item_cost'] / pw.loc[dorman_update_idx, 'PackQty']\n",
    "\n",
    "# Make a \"backup\" copy of cs-sku-np for CatSKU situations\n",
    "pw['CS-SKU-NP-CatSKU'] = pw['CS-SKU-NP']\n",
    "\n",
    "# Set CSSKUNP depending on if it's a punctuation warehouse\n",
    "x = pw[pw['WD'].isin(PUNCTUATION_WAREHOUSES)].copy()\n",
    "x['CS-SKU-NP'] = x['WD'] + x['MasterLC'].astype(str) + '|' + x['Part Number']\n",
    "pw.loc[pw['WD'].isin(PUNCTUATION_WAREHOUSES), :] = x\n",
    "\n",
    "x = pw[~pw['WD'].isin(PUNCTUATION_WAREHOUSES)].copy()\n",
    "x['CS-SKU-NP'] = (x['WD'] + x['MasterLC'].astype(str) + '|' \n",
    "                  + x['Part Number'].map(lambda s: ''.join(filter(str.isalnum, s))))\n",
    "pw.loc[~pw['WD'].isin(PUNCTUATION_WAREHOUSES), :] = x\n",
    "\n",
    "maps = []\n",
    "for i, row in pw.iterrows():\n",
    "    csskunp = row['CS-SKU-NP']\n",
    "    if csskunp in map_prices:\n",
    "        maps.append(map_prices[csskunp])\n",
    "    else:\n",
    "        maps.append(1)\n",
    "pw['MAP'] = maps\n",
    "\n",
    "# Remove WeatherTech (just in case)\n",
    "pw = pw[pw['MasterLC'] != 310]\n",
    "\n",
    "# Remove First Stop Brakes Dorman Line\n",
    "# df = df[~((df['WD']=='D') & df['Part Number'].isin(first_stop_brakes))]\n",
    "# Nope, actually don't remove them, just set MinQty really high... at the end.\n",
    "\n",
    "# Remove placeholder values for Weight/ShipWeight\n",
    "pw.loc[(pw['Weight']==9999), 'Weight'] = np.nan\n",
    "pw.loc[(pw['ShipWeight']==9999), 'ShipWeight'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-nirvana",
   "metadata": {},
   "source": [
    "#### Filter parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "progressive-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea here is to filter out all the lil nasties that we don't want to include.\n",
    "# This could differ by warehouse, or not.\n",
    "# Things like, heavy parts, big or oddly shaped parts, \n",
    "# parts that are really expensive, or come in packs of many.\n",
    "# ... See notes on original Jim conversation for what all you should be including here.\n",
    "\n",
    "# Filter out excluded warehouses.\n",
    "pw = pw[~pw['WD'].isin(EXCLUDED_WAREHOUSES)]\n",
    "# Filter out nasty pack quantities. (allow these for Dorman, since we have clean data.)\n",
    "pw['PackQty'] = pw['PackQty'].fillna(1) # assume PackQty of NA => PackQty=1\n",
    "pw = pw[(pw['PackQty'] <= 10) | (pw['WD']=='D')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-palestine",
   "metadata": {},
   "source": [
    "#### Calculate shipping by warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d407c34-6fa1-4dca-93ec-997f1dec1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_data = pd.read_csv('shipping_data.csv', low_memory=False, parse_dates=['Ship Date'])\n",
    "shipping_data['warehouse_key'] = shipping_data['Warehouse'].map(get_warehouse_key)\n",
    "shipping_data = shipping_data[shipping_data['Quantity'] > 0]\n",
    "shipping_data['Ship Cost'] = shipping_data['Ship Cost'] / shipping_data['Quantity']\n",
    "shipping_data = shipping_data[shipping_data['Ship Cost'] > 0.05][['CS-SKU','warehouse_key','Ship Cost','Ship Date']]\n",
    "\n",
    "price_file_shipping = pd.read_csv('price-file-shipping.csv')\n",
    "price_file_shipping = {row['CS-SKU-NP']: row['Shipping'] for _, row in price_file_shipping.iterrows()}\n",
    "\n",
    "def get_historical_shipping_estimates(df, warehouse_key): # (cssku, warehouse_key):    \n",
    "    warehouse_shipping_data = shipping_data[(shipping_data['warehouse_key']==warehouse_key)].copy()\n",
    "    # create warehouse-level shipping model\n",
    "    feature_cols = ['Weight', 'DimWeight', 'ShipWeight', 'Length', 'Width', 'Height']\n",
    "    ship_weights = df[['MasterSKU']+feature_cols].merge(warehouse_shipping_data, how='inner',\n",
    "                                                        left_on='MasterSKU', right_on='CS-SKU').copy().dropna()\n",
    "    ship_weights = ship_weights[(ship_weights['ShipWeight'] > 0) & (ship_weights['ShipWeight'] < 1000)]\n",
    "    if len(ship_weights) > 0:\n",
    "        model = LinearRegression().fit(ship_weights[feature_cols], ship_weights['Ship Cost'])\n",
    "        # log model error for audit purposes\n",
    "        print('RMSE:',mean_squared_error(ship_weights['Ship Cost'], \n",
    "                                         model.predict(ship_weights[feature_cols]), squared=False))\n",
    "    else:\n",
    "        model = None\n",
    "\n",
    "    shipping_estimates = []\n",
    "    for _, row in df.iterrows():\n",
    "        cssku = row['MasterSKU']\n",
    "        order_history = warehouse_shipping_data[(warehouse_shipping_data['CS-SKU']==cssku)]\n",
    "        \n",
    "        \n",
    "        # First, check most recent price files for shipping info.\n",
    "        # This allows for a gradual transition into the new price file scheme.\n",
    "        if f'{warehouse_key}{cssku}' in price_file_shipping:\n",
    "            shipping_estimates.append(price_file_shipping[f'{warehouse_key}{cssku}'])\n",
    "        \n",
    "        elif len(order_history) > 0:\n",
    "            # if we have historicals on this one, just take the mean\n",
    "            shipping_estimates.append(order_history['Ship Cost'].mean())\n",
    "        elif model:\n",
    "            # if not, then estimate it using all other skus for this warehouse, with weight/dim\n",
    "            shipping_estimates.append(model.predict(row[feature_cols].fillna(0).values.reshape(1, -1))[0])\n",
    "        elif len(warehouse_shipping_data['Ship Cost']) > 0:\n",
    "            # and if no model available, just use average\n",
    "            shipping_estimates.append(warehouse_shipping_data['Ship Cost'].mean())\n",
    "        else:\n",
    "            shipping_estimates.append(10) # baseline of $10... ??\n",
    "\n",
    "    df['Shipping'] = shipping_estimates\n",
    "    return df['Shipping']\n",
    "\n",
    "# Expects something formatted like a price/weight DF, filtered for a warehouse\n",
    "# returns the price/weight DF with shipping altered\n",
    "def calculate_warehouse_shipping(df, warehouse):\n",
    "\n",
    "    df = df.copy()\n",
    "    print(warehouse)\n",
    "    if warehouse=='D': # Dorman\n",
    "        df.loc[(df['item_cost'] <= 30), ['Shipping', 'ShipMkup']] = 6, DEFAULT_SHIP_MARKUP # flat rate\n",
    "        df.loc[(df['item_cost'] > 30), ['Shipping', 'ShipMkup']] = 0, 1\n",
    "        ##df['ShipMkup'] = 1\n",
    "    elif warehouse=='C': # Brock\n",
    "        df.loc[(df['item_cost'] <= 50), 'Shipping'] = 16 # estimate / avg.\n",
    "        df.loc[(df['item_cost'] > 50), 'Shipping'] = 0\n",
    "        df['ShipMkup'] = 1 / 1.1 # to account for returns not being accepted\n",
    "    elif warehouse=='P': # Parts Auth\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "        '''\n",
    "        with open(PARTS_AUTH_SHIPPING_MODEL, 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "        df['lwh'] = df['Length'] * df['Width'] * df['Height']\n",
    "        df['Shipping'] = m.predict(df[['Weight','Length','Width','Height','lwh']].fillna(0))\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "        '''\n",
    "    elif warehouse=='1': # Jante\n",
    "        df['Shipping'] = 0\n",
    "        df['ShipMkup'] = 1\n",
    "    elif warehouse=='J': # PFG\n",
    "        PFG_DEFAULT_SHIPPING = 15\n",
    "        inv = pd.read_csv('inventory/pfg.txt', sep='\\t', encoding_errors='ignore', escapechar = '\\\\', low_memory=False)[['SKU','SHIPPING_COST','HANDLING_COST']]\n",
    "        parts = inv['SKU'].values\n",
    "        shippings = []\n",
    "        for _, row in df.iterrows():\n",
    "            pn = row['Part Number']\n",
    "            if pn in parts:\n",
    "                shippings.append(inv[inv['SKU']==pn].iloc[0][['SHIPPING_COST','HANDLING_COST']].sum())\n",
    "            else:\n",
    "                shippings.append(PFG_DEFAULT_SHIPPING)\n",
    "        df['Shipping'] = shippings\n",
    "    \n",
    "        # ADD AN EXTRA $3.50 TO ACCOUNT FOR TAX MESS\n",
    "        df['Shipping'] = df['Shipping'] + 3.50 \n",
    "        \n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    elif warehouse=='K': # Keystone\n",
    "        KEYSTONE_BASE_SHIPPING = 11.0\n",
    "        KEYSTONE_LTL_SHIPPING = 125.0\n",
    "        inv = pd.read_csv('inventory/keystone.csv', low_memory=False)\n",
    "        # Since inventory file open, manage duplicate part # issue in Keystone by matching with UPC\n",
    "        inv['PartNumber'] = inv['PartNumber'].str.replace('=','').str.replace('\"','')\n",
    "        ##inv['KeystoneShipping'] = (inv['UPS_Ground_Assessorial'] + KEYSTONE_BASE_SHIPPING).fillna(0)\n",
    "        inv['KeystoneShipping'] = (KEYSTONE_BASE_SHIPPING)\n",
    "        inv.loc[inv['UPSable']==False, 'KeystoneShipping'] = KEYSTONE_LTL_SHIPPING\n",
    "        inv = inv.sort_values('KeystoneShipping', ascending=False).drop_duplicates(subset=['VendorCode','PartNumber'])\n",
    "        df = df.merge(inv[['VendorCode','PartNumber','KeystoneShipping']], \n",
    "                      how='left', left_on=['LC','Part Number'], right_on=['VendorCode','PartNumber'])\n",
    "        df['Shipping'] = df['KeystoneShipping']\n",
    "        df['ShipMkup'] = 1\n",
    "\n",
    "    elif warehouse=='6': # Burco Mirrors\n",
    "        #df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        #df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "        df['Shipping'] = 8 # estimate / avg\n",
    "        df['ShipMkup'] = 1\n",
    "    elif warehouse=='A': # APW\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    elif warehouse=='2': # OE Wheels\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    elif warehouse=='5': # KSI Trading\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    \n",
    "    elif warehouse=='7': # NTW\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    elif warehouse=='8': # Race Sport Lighting\n",
    "        ##df['Shipping'] = df['Weight'].map(lambda w: 15 if (pd.isna(w) or w >= 1) else 6)\n",
    "        ##df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "        df['Shipping'] = 18\n",
    "        df['ShipMkup'] = 1\n",
    "    elif warehouse=='9': # Sunbelt APG\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    \n",
    "    elif warehouse=='N': # NPW\n",
    "        ##df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df.loc[df['LC']=='ACD', 'Shipping'] = 35 # set AC Delco skus to $35 shipping\n",
    "        df['Shipping'] = 12\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "    \n",
    "    elif warehouse=='O': # Tonsa\n",
    "        df['Shipping'] = get_historical_shipping_estimates(df, warehouse)\n",
    "        df['ShipMkup'] = DEFAULT_SHIP_MARKUP\n",
    "\n",
    "    elif warehouse=='Y': # MotorState\n",
    "        df.loc[(df['item_cost'] <= 39), 'Shipping'] = 13\n",
    "        df.loc[((df['item_cost'] > 39) & (df['item_cost'] <= 99.99)), 'Shipping'] = 11.5\n",
    "        df.loc[(df['item_cost'] >= 100), 'Shipping'] = 10\n",
    "        df['ShipMkup'] = 1\n",
    "    else:\n",
    "        pass\n",
    "    df['ShipMkup'] = df['ShipMkup'].fillna(1)\n",
    "    return df[['Shipping','ShipMkup']]\n",
    "\n",
    "dfs = []\n",
    "for warehouse in pw['WD'].unique().tolist():\n",
    "    wdf = pw[pw['WD']==warehouse].copy()\n",
    "    wdf.loc[:, ['Shipping','ShipMkup']] = calculate_warehouse_shipping(wdf.loc[wdf['WD']==warehouse, :], \n",
    "                                                                           warehouse).values\n",
    "    print('Proportion of parts missing shipping:', wdf['Shipping'].isna().mean())\n",
    "    dfs.append(wdf)\n",
    "pw = pd.concat(dfs, ignore_index=True)\n",
    "pw['ShipMkup'] = pw['ShipMkup'].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-female",
   "metadata": {},
   "source": [
    "#### Set inventory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[:, ['MinQty','MaxQty']] = 2, 12 ## Changed Min to two from 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-mumbai",
   "metadata": {},
   "source": [
    "#### Set price file defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw['ListMkup'] = .65\n",
    "pw['SourceQty'] = None\n",
    "pw['Source'] = None\n",
    "pw['BundleSK'] = None\n",
    "pw['Carrier'] = 'FedEx'\n",
    "pw['Service'] = 'GroundHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[(pw['CS-SKU-NP'].str[0]=='D'), ['OP-Lowest(Y)','VND-Lowest(Y)'] ] = \"N\", \"N\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-coordinate",
   "metadata": {},
   "source": [
    "## Quick fix for shipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-staff",
   "metadata": {},
   "source": [
    "Where shipping is current zero for Tonsa, set it to 20. And 15 for Sunbelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[((pw['Shipping'] == 0) & (pw['CS-SKU-NP'].str[0] == 'O')), 'Shipping'] = 20\n",
    "pw.loc[((pw['Shipping'] == 0) & (pw['CS-SKU-NP'].str[0] == '9')), 'Shipping'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-mongolia",
   "metadata": {},
   "source": [
    "1.5x Tonsa, Sunbelt, and Parts Auth shipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[(pw['CS-SKU-NP'].str[0]=='P'), 'Shipping'] *= 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-aluminum",
   "metadata": {},
   "source": [
    "Double Eagle Eye Shipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[(pw['CS-SKU-NP'].str[:4]=='P754'), 'Shipping'] *= 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-exemption",
   "metadata": {},
   "source": [
    "Bumper is expensive to ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='429|6448-0006', 'Shipping'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-government",
   "metadata": {},
   "source": [
    "Another expensive shipping update from order: PSA669874628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='551|S6585B', 'Shipping'] = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e8265",
   "metadata": {},
   "source": [
    "Manual SKU Changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b237b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P576|3292', 'Shipping'] = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022907cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P550|290073', 'Shipping'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P308|55621', 'Shipping'] = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b061cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P557|277504', 'Shipping'] = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dfe016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P643|ESK5752', 'Shipping'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30750742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P551|40722A', 'Shipping'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='N643|AR8265XPR', 'PackQty'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[pw['CS-SKU-NP']=='P123|33660', 'PackQty'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbe515",
   "metadata": {},
   "source": [
    "PA Shipping Costs from Umer analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_shipping_data = pd.read_csv('PA Shipping Costs.csv', low_memory=False)\n",
    "pa_shipping_data['WD'] = 'P'\n",
    "\n",
    "pa_shipping_data = pa_shipping_data.sort_values(by='Row Labels', ascending=False)\n",
    "pa_shipping_data.drop_duplicates(subset='Final Shipping Cost', keep=\"first\")\n",
    "\n",
    "pw = pw.merge(pa_shipping_data, how='left', left_on=['MasterSKU', 'WD'], right_on=['Row Labels', 'WD'])\n",
    "pw.loc[pw['Final Shipping Cost'] > 0, 'Shipping'] = pw['Final Shipping Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db777",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shipping = pd.read_csv('newshipcosts.csv', low_memory=False)\n",
    "\n",
    "pw = pw.merge(new_shipping, how='left', left_on=['MasterSKU'], right_on=['CS_SKU'])\n",
    "pw.loc[pw['NewShipCost'] > 0, 'Shipping'] = pw['NewShipCost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-convenience",
   "metadata": {},
   "source": [
    "Set MinQty really high for First Stop Brakes (Dorman line) to avoid actually selling any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stop_brakes = pd.read_excel('8-2 Change 56 Brake Dropship and Stocking.xlsx', \n",
    "                                  skiprows=2, sheet_name='Dropship Price').rename(columns={'MATERIAL':'pn'})['pn']\n",
    "pw.loc[(pw['WD']=='D') & pw['Part Number'].isin(first_stop_brakes), ['MinQty','MaxQty']] = 100, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347dcb1",
   "metadata": {},
   "source": [
    "Handle RSL skus for MAP > Calculated Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsl_inventory = pd.read_csv('inventory/rsl.csv', low_memory=False)\n",
    "rsl_inventory = rsl_inventory.to_dict('records')\n",
    "rsl_skus_map_price = []\n",
    "\n",
    "for row in rsl_inventory:\n",
    "    if (\"8329|\" + row['SKU']) in pw['CS-SKU-NP'].values:\n",
    "        matched_rsl = pw.loc[pw['CS-SKU-NP'] == \"8329|\" + row['SKU']]\n",
    "        pw_item_cost = matched_rsl['item_cost'].values[0]\n",
    "        pw_shipping = matched_rsl['Shipping'].values[0]\n",
    "        markup = pw_item_cost / ( (1 + 0.05) * (pw_item_cost + pw_shipping) / (1 - 0.15) - pw_shipping)\n",
    "        if (pw_item_cost / markup) + (pw_shipping / matched_rsl['ShipMkup'].values[0]) < row['MAP']:\n",
    "            pw.loc[pw['CS-SKU-NP'] == \"8329|\" + row['SKU'], ['MinPrice', 'item_cost', 'Shipping', 'ShipMkup']] = row['MAP'], row['MAP'], 0, 0\n",
    "            rsl_skus_map_price.append(\"8329|\" + row['SKU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9923ff",
   "metadata": {},
   "source": [
    "Motorstate Formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe847360-404b-4ed0-966c-2fb279e81b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorstate = pd.read_csv('inventory/motorstate.csv', low_memory=False)\n",
    "#motorstate['PartNumber'] = motorstate.PartNumber.str[3:]\n",
    "motorstate['PartNumber'] = 'Y' + motorstate['PartNumber']\n",
    "motorstate\n",
    "#pw = pw.merge(motorstate, how='left', left_on=['Part Number', 'WD'], right_on=['PartNumber', 'WD'])\n",
    "\n",
    "\n",
    "pw['tkey'] = pw['WD'] + pw['LC'] + pw['Part Number']\n",
    "pw_cols = pw.columns\n",
    "pw = pw.merge(motorstate, how='left', left_on=['tkey'], right_on=['PartNumber'])\n",
    "pw.drop(columns='tkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78deacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.drop(pw.loc[pw['AirRestricted'] == 'YES'].index, inplace=True)\n",
    "pw.drop(pw.loc[pw['TruckFrtOnly'] == 'YES'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.drop(pw.loc[(pw['WD'] == 'Y') & (pw['MasterLC'] != 261)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19371ec",
   "metadata": {},
   "source": [
    "NPW Min Order Qty"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d054250e-0fa4-4bd6-bb31-e156f6c1e7da",
   "metadata": {},
   "source": [
    "'''\n",
    "npw_inventory = pd.read_csv('inventory/npw.csv', low_memory=False)\n",
    "npw_inventory['WD'] = 'N'\n",
    "\n",
    "pw = pw.merge(npw_inventory, how='left', left_on=['Part Number', 'WD', 'LC'], right_on=['SKU_noDS', 'WD', 'Line_code'])\n",
    "pw.loc[pw['Min_order_Qty'] > 1,['MinPrice','Cost']] = (pw['MinPrice'] + pw['Core_cost']) * pw['Min_order_Qty']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e62bab",
   "metadata": {},
   "source": [
    "OE wheels price MAP fix 11/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_wheel_update = pd.read_excel('OE Wheel Shipping.xlsx', sheet_name='Sheet1')\n",
    "oe_wheel_update = oe_wheel_update.to_dict('records')\n",
    "\n",
    "for row in oe_wheel_update:\n",
    "    if pw['CS-SKU-NP'].isin([\"2387|\" + str(row['UPC'])]).any:\n",
    "        pw.loc[pw['CS-SKU-NP'] == \"2387|\" + str(row['UPC']), 'Shipping'] = row['Shipping (Est)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bbe3a",
   "metadata": {},
   "source": [
    "Fix for Batteries shipping costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a873ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batteries = pd.read_excel('Input File PA Battery.xlsx', sheet_name='Sheet1')\n",
    "batteries['Part'] = batteries['Part'].str.replace('-','')\n",
    "batteries = batteries.to_dict('records')\n",
    "\n",
    "for row in batteries:\n",
    "    print(row['Part'])\n",
    "    if pd.isna(row['Part']) == False and pw['CS-SKU-NP'].str[5:].isin([row['Part']]).any:\n",
    "        pw.loc[pw['CS-SKU-NP'].str.contains(row['Part']), 'Shipping'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8449c15",
   "metadata": {},
   "source": [
    "OE Wheels 4PLAY 20% Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "oe_wheels_discount = pd.read_csv('4PLAY Wheels - Sheet1.csv', low_memory=False)\n",
    "oe_wheels_discount = oe_wheels_discount.to_dict('records')\n",
    "\n",
    "for row in oe_wheels_discount:\n",
    "    if pw['CS-SKU'].isin([\"2\" + row['4Play wheels']]).any:\n",
    "        wheel_result = pw.loc[pw['CS-SKU'] == \"2\" + row['4Play wheels']]\n",
    "        print(wheel_result['MinPrice'].values[0])\n",
    "        twenty_percent = (wheel_result['MinPrice'].values[0] / 10) * 2\n",
    "        print(twenty_percent)\n",
    "        pw.loc[pw['CS-SKU'] == \"2\" + row['4Play wheels'], ['MinPrice', 'MAP']] = wheel_result['MinPrice'].values[0] - twenty_percent, wheel_result['MinPrice'].values[0] - twenty_percent\n",
    "'''        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb0d0b",
   "metadata": {},
   "source": [
    "Use PA Inventory file for PackQtys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a31c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_inv = pd.read_csv('inventory/pa.csv', low_memory=False, encoding= 'unicode_escape')\n",
    "pa_inv['Part'] = pa_inv['Part'].replace('-', '', regex=True)\n",
    "\n",
    "\n",
    "pw = pw.merge(pa_inv, how='left', left_on=['Part Number', 'LC'], right_on=['Part', 'Line'])\n",
    "pw.loc[pw['Packs'] > 1, 'PackQty'] = pw['Packs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30aaacb",
   "metadata": {},
   "source": [
    "Force shipping cost and ship markup for RSL Skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.loc[(pw['WD'] == '8') & (pw['Shipping'] == 0), ['Shipping', 'ShipMkup']] = 18, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-pioneer",
   "metadata": {},
   "source": [
    "#### Calculate markups and format/write price files, by channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "noncats = pd.read_csv('non-cat-skus.csv', skiprows=1, low_memory=False)[['CS Linecode','Part Number']]\n",
    "noncats['cssku'] = noncats['CS Linecode'] + '|' + noncats['Part Number']\n",
    "noncat_skus = noncats['cssku'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a540ba3-63ea-4551-bbb9-ec4b7a197278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-receipt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for channel in CHANNELS:\n",
    "    pf = pw.copy()\n",
    "    \n",
    "    # Filter price file if APF or Mecka\n",
    "    if channel['name'] == 'AP Fusion':\n",
    "        apf_csskus = pd.read_csv('apf-skus.csv')['cssku']\n",
    "        apf_csskus = apf_csskus.drop_duplicates()\n",
    "        pf = pf[pf['CS-SKU-NP'].str[1:].isin(apf_csskus)]\n",
    "    if channel['name'] == 'Mecka':\n",
    "        pf = pf[(pf['WD']=='D') & (pf['item_cost'] >= 30)]\n",
    "    # FIlter BS Walmart \n",
    "    if channel['name'] == 'BS Walmart':\n",
    "        print(channel['name'])\n",
    "        pf.drop(pf.loc[pf['WD'] == 'Y'].index, inplace=True)\n",
    "        ##pf.drop(pf.loc[pf['WD'] == 'P'].index, inplace=True)\n",
    "        pf.drop(pf.loc[pf['WD'] == 'J'].index, inplace=True)\n",
    "        pf.drop(pf.loc[pf['WD'] == 'C'].index, inplace=True)\n",
    "        pf.drop(pf.loc[pf['WD'] == '8'].index, inplace=True)\n",
    "\n",
    "    # Calculate markups\n",
    "    target_profit = channel['target_profit'] if 'target_profit' in channel else DEFAULT_TARGET_PROFIT\n",
    "    channel_fees = channel['channel_transaction_fee'] + CS_TRANSACTION_FEE\n",
    "    markups = []\n",
    "    for _, row in pf.iterrows():\n",
    "        # handle brock specially\n",
    "        if row['CS-SKU-NP'][0] == 'C':\n",
    "            our_cost = row['item_cost']\n",
    "            if row['item_cost'] <= 50: # + $6 for any item costing < $40\n",
    "                our_cost += 4\n",
    "            our_cost *= 1.1 # 10% marup for all items, as buffer against no-return policy\n",
    "            # calculate markup using same formula but with our updated cost value\n",
    "            our_markup = our_cost / ( (1 + target_profit) * (our_cost + row['Shipping']) / (1 - channel_fees) - row['Shipping'])\n",
    "            # then adjust to find what the equivalent markup would be (to get to same final price) with the original cost value\n",
    "            markup = row['item_cost'] * our_markup / our_cost\n",
    "        \n",
    "        # handle Jante, certain skus specially\n",
    "        elif ( channel['name'] == 'PS Ebay' and row['CS-SKU-NP'][:4] == '1367' ):\n",
    "            ##markup = row['item_cost'] / ( (1 + target_profit) * (row['item_cost'] + row['Shipping']) / (1 - (channel_fees - .02)) - row['Shipping'])\n",
    "            markup = row['item_cost'] / ( (1 + target_profit) * (row['item_cost'] + row['Shipping']) / (1 - channel_fees) - row['Shipping'])\n",
    "        # Added 1% more to channel fees\n",
    "        elif ( channel['name'] == 'PS Ebay' and row['CS-SKU-NP'][0] == '1' ):\n",
    "            markup = row['item_cost'] / ( (1 + target_profit) * (row['item_cost'] + row['Shipping']) / (1 - (channel_fees + 0.01)) - row['Shipping'])\n",
    "        # Dorman increase profit\n",
    "        elif row['CS-SKU-NP'][0] == 'D':\n",
    "            markup = row['item_cost'] / ( (1 + 0.06) * (row['item_cost'] + row['Shipping']) / (1 - channel_fees) - row['Shipping'])  \n",
    "            \n",
    "        # base case, all other skus\n",
    "        else:\n",
    "            markup = row['item_cost'] / ( (1 + target_profit) * (row['item_cost'] + row['Shipping']) / (1 - channel_fees) - row['Shipping'])\n",
    "\n",
    "        markups.append(markup)\n",
    "    pf['Markup'] = markups\n",
    "    \n",
    "    # Format price file.\n",
    "    if channel['name'] in CatSKU_CHANNELS:\n",
    "        pf['CatSKU'] = (~pf['CS-SKU-NP'].str[1:].isin(noncat_skus)).map(lambda x: 'Y' if x else 'N')\n",
    "        pf.loc[pf['CatSKU']=='Y', 'CS-SKU-NP'] = pf.loc[pf['CatSKU']=='Y', 'CS-SKU-NP-CatSKU']\n",
    "    else:\n",
    "        pf['CatSKU'] = 'N'\n",
    "    \n",
    "    # Clean up\n",
    "    pf.loc[pf['MinPrice'] < 1,'MinPrice'] = 1\n",
    "    pf.loc[pf['Markup'] < .1,'Markup'] = .1\n",
    "    pf.loc[pf['Markup'] > 1,'Markup'] = 1\n",
    "    pf['Markup'] = pf['Markup'].round(3)\n",
    "    pf['Shipping'] = pf['Shipping'].round(2)\n",
    "    pf.loc[pf['Shipping'].lt(0), 'Shipping'] = 0\n",
    "    pf['total_cost'] = pf['item_cost'] + pf['Shipping'] # hoping this will fix most examples of Dorman going thru PA\n",
    "    \n",
    "    # give dorman direct preference over dorman skus from other warehouses\n",
    "    \n",
    "    #Dorman Pref - Original\n",
    "    #dorman_prefs = pw[(pw['WD']=='D') & (pw['Qty'] > 0)]['MasterSKU'].copy().tolist()\n",
    "    #pw = pw[~((pw['WD'] != 'D') & (pw['MasterSKU'].isin(dorman_prefs)))] \n",
    "    \n",
    "    #Dorman Pref - Corrected\n",
    "    dorman_prefs = pf[(pf['WD']=='D') & (pf['Qty'] > 0)]['MasterSKU'].copy().tolist()\n",
    "    pf = pf[~((pf['WD'] != 'D') & (pf['MasterSKU'].isin(dorman_prefs)))]   #Corrected - The change should be wpplied on current price file, not pw\n",
    "    \n",
    "    pf = pf.sort_values(['MasterSKU','Qty','total_cost'], ascending=[True,False,True])\\\n",
    "           .drop_duplicates(subset=['MasterSKU'], keep='first')\n",
    "    \n",
    "    pf = pf[PRICE_FILE_COLUMNS]\n",
    "    \n",
    "    # Write price file.\n",
    "    pf.to_csv(f\"{PRICE_FILE_LOCATION}/{channel['name']}.csv\", index=False)\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f95902-40eb-4422-bf6a-990c296925d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1603d0be3227fab8159d0092641500a55c974a65b8b6791f95fc8c8f1af5acb6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
